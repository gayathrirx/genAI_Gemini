{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974ac24-0b81-43eb-a8b3-5bc86d402552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required python packages\n",
    "!pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c92d0b4-d250-4a29-ae4b-5f296f14e896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart the kernet after libraries are loaded\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b4c364-eba0-4c62-85b7-f7c2c25b1e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# import software libraries required\n",
    "import requests\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    FunctionDeclaration,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d402d35-2356-47d5-973d-b69c106087f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Prompt--------\n",
      "Why is the sky blue?.\n",
      "\n",
      "-------Response--------\n",
      "The sky appears blue due to a phenomenon called Rayleigh scattering. Sunlight, which is white light, is composed of all colors of the rainbow. When sunlight enters the Earth's atmosphere, it interacts with the tiny molecules of air, such as nitrogen and oxygen. These molecules scatter the light in all directions. \n",
      "\n",
      "However, blue light has a shorter wavelength than other colors, so it is scattered more strongly by the air molecules. This means that more blue light reaches our eyes from the sky than any other color. As a result, the sky appears blue to us.\n",
      "\n",
      "Here are some additional details about the scattering of light:\n",
      "\n",
      "* The amount of scattering depends on the size of the particles and the wavelength of light. Smaller particles scatter shorter wavelengths more strongly, while larger particles scatter longer wavelengths more strongly.\n",
      "* The intensity of scattered light is inversely proportional to the fourth power of the wavelength. This means that blue light, which has a shorter wavelength, is scattered about 16 times more strongly than red light, which has a longer wavelength.\n",
      "* Rayleigh scattering is also responsible for the red color of the sunset. As the sun sets, sunlight has to travel through a thicker layer of atmosphere, which scatters most of the blue light away. This leaves the red light, which is scattered less strongly, to reach our eyes.\n",
      "\n",
      "Here are some additional resources that you may find helpful:\n",
      "\n",
      "* NASA Space Place: Why Is the Sky Blue? https://spaceplace.nasa.gov/blue-sky/\n",
      "* NOAA SciJinks: Why Is the Sky Blue? https://scijinks.gov/blue-sky/\n",
      "* Royal Observatory: Why is the sky blue? https://www.rmg.co.uk/stories/topics/why-sky-blue\n",
      "\n",
      "I hope this information is helpful! Let me know if you have any other questions."
     ]
    }
   ],
   "source": [
    "# Task 2.1\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "\n",
    "prompt = \"Why is the sky blue?.\"\n",
    "\n",
    "\n",
    "responses=model.generate_content(prompt, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print(prompt)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fcef55b-2fd3-4357-b62d-c8a48d388f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2.2\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "get_current_weather_func = FunctionDeclaration(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Get the current weather in a given location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Location\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6dcf2f0-1b02-49c3-abf1-646403ca47d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 2.3\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "weather_tool = Tool(\n",
    "    function_declarations=[get_current_weather_func],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fcd435f-43e9-4775-902c-42575bd2f61f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      function_call {\n",
       "        name: \"get_current_weather\"\n",
       "        args {\n",
       "          fields {\n",
       "            key: \"location\"\n",
       "            value {\n",
       "              string_value: \"Boston\"\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0950130522\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0840406194\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.151906386\n",
       "    severity: HARM_SEVERITY_LOW\n",
       "    severity_score: 0.207535744\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.138578326\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0826973394\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0291459728\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0513675064\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 23\n",
       "  candidates_token_count: 7\n",
       "  total_token_count: 30\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2.4\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling#function-calling-generation-sdk-sample\n",
    "prompt = \"What is the weather like in Boston?\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config={\"temperature\": 0},\n",
    "    tools=[weather_tool],\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e627baf8-cccb-467f-8ebe-cc4b3906ff33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Run the following cell to import required libraries \n",
    "from vertexai.preview.generative_models import (\n",
    "    GenerationConfig,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d306edd-9888-4346-beab-120009fdb630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.1\n",
    "# Load the correct Gemini model use the following documentation to assist:\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview#supported-use-cases\n",
    "multimodal_model = GenerativeModel(\"gemini-1.0-pro-vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed775b0-d63a-4a6a-9a55-8fe85ba0304b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Image):\n",
    "        return False\n",
    "    display_images([content])\n",
    "    return True\n",
    "\n",
    "\n",
    "def display_content_as_video(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Part):\n",
    "        return False\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
    "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list[str | Image | Part]):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if display_content_as_image(content):\n",
    "            continue\n",
    "        if display_content_as_video(content):\n",
    "            continue\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e0a91-d216-4a48-a7de-587cb9d6782e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Prompt--------\n",
      "\n",
      "What is shown in this video?\n",
      "Where should I go to see it?\n",
      "What are the top 5 places in the world that look like this?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\" controls  width=\"600\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2 Generate a video description\n",
    "# In this cell, update the prompt to ask Gemini to describe the video URL referenced.\n",
    "# You can use the documentation at the following link to assist.\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview-reference#generate-content-from-video\n",
    "# \n",
    "# Video URI: gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\n",
    "# \n",
    "prompt = \"\"\"\n",
    "What is shown in this video?\n",
    "Where should I go to see it?\n",
    "What are the top 5 places in the world that look like this?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = multimodal_model.generate_content(contents, stream=True)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7986bb-1ca7-4ea3-b31c-891bc1fb158a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-15.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-15:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
